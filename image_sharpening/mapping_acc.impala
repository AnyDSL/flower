fn iteration1f1i(out: Img, arr: Imgi16,
                 body: fn(i32, i32, Acc, Acci16) -> ()
                ) -> () {
    let unroll = 1;
    let grid   = (out.width, out.height/unroll, 1);
    let block  = (32, 4, 1);

    let out_gpu = get_img    (alloc_cuda(acc_dev(), out.width * out.height * 4), out.width, out.height);
    let arr_gpu = get_img_i16(alloc_cuda(acc_dev(), arr.width * arr.height * 2), arr.width, arr.height);
    copy(arr.buf, arr_gpu.buf, arr.width * arr.height * 2);

    for benchmark_acc() {
        acc(acc_dev(), grid, block, || @{
            let gid_x = acc_gidx();
            let gid_y = acc_tidy() + acc_bdimy() * acc_bidy() * unroll;
            let out_acc = get_acc    (out_gpu, 10);
            let arr_acc = get_acc_i16(arr_gpu, 10);

            for i in range(0, unroll) {
                body(gid_x, gid_y + i * acc_bdimy(), out_acc, arr_acc);
            }
        });
    }

    copy(out_gpu.buf, out.buf, out.width * out.height * 4);
    release(out_gpu.buf);
    release(arr_gpu.buf);
}
fn iteration2i(out: Imgi16, arr: Imgi16,
               body: fn(i32, i32, Acci16, Acci16) -> ()
              ) -> () {
    let unroll = 1;
    let grid   = (out.width, out.height/unroll, 1);
    let block  = (32, 4, 1);

    let out_gpu = get_img_i16(alloc_cuda(acc_dev(), out.width * out.height * 2), out.width, out.height);
    let arr_gpu = get_img_i16(alloc_cuda(acc_dev(), arr.width * arr.height * 2), arr.width, arr.height);
    copy(arr.buf, arr_gpu.buf, arr.width * arr.height * 2);

    for benchmark_acc() {
        acc(acc_dev(), grid, block, || @{
            let gid_x = acc_gidx();
            let gid_y = acc_tidy() + acc_bdimy() * acc_bidy() * unroll;
            let out_acc = get_acc_i16(out_gpu, 10);
            let arr_acc = get_acc_i16(arr_gpu, 10);

            for i in range(0, unroll) {
                body(gid_x, gid_y + i * acc_bdimy(), out_acc, arr_acc);
            }
        });
    }

    copy(out_gpu.buf, out.buf, out.width * out.height * 2);
    release(out_gpu.buf);
    release(arr_gpu.buf);
}
fn iteration2i1m(out: Imgi16, img: Imgi16, map: Img,
                 body: fn(i32, i32, Acci16, Acci16, Acc) -> ()
                ) -> () {
    let unroll = 1;
    let grid   = (out.width, out.height/unroll, 1);
    let block  = (32, 4, 1);

    let out_gpu = get_img_i16(alloc_cuda(acc_dev(), out.width * out.height * 2), out.width, out.height);
    let img_gpu = get_img_i16(alloc_cuda(acc_dev(), img.width * img.height * 2), img.width, img.height);
    let map_gpu = get_img    (alloc_cuda(acc_dev(), map.width * map.height * 4), map.width, map.height);
    copy(img.buf, img_gpu.buf, img.width * img.height * 2);
    copy(map.buf, map_gpu.buf, map.width * map.height * 2);

    for benchmark_acc() {
        acc(acc_dev(), grid, block, || @{
            let gid_x = acc_gidx();
            let gid_y = acc_tidy() + acc_bdimy() * acc_bidy() * unroll;
            let out_acc = get_acc_i16(out_gpu, 10);
            let img_acc = get_acc_i16(img_gpu, 10);
            let map_acc = get_acc    (map_gpu, 10);

            for i in range(0, unroll) {
                body(gid_x, gid_y + i * acc_bdimy(), out_acc, img_acc, map_acc);
            }
        });
    }

    copy(out_gpu.buf, out.buf, out.width * out.height * 2);
    release(out_gpu.buf);
    release(img_gpu.buf);
    release(map_gpu.buf);
}
fn iteration3i(out: Imgi16, img: Imgi16, tmp: Imgi16,
               body: fn(i32, i32, Acci16, Acci16, Acci16) -> ()
              ) -> () {
    let unroll = 1;
    let grid   = (out.width, out.height/unroll, 1);
    let block  = (32, 4, 1);

    let out_gpu = get_img_i16(alloc_cuda(acc_dev(), out.width * out.height * 2), out.width, out.height);
    let img_gpu = get_img_i16(alloc_cuda(acc_dev(), img.width * img.height * 2), img.width, img.height);
    let tmp_gpu = get_img_i16(alloc_cuda(acc_dev(), tmp.width * tmp.height * 2), tmp.width, tmp.height);
    copy(img.buf, img_gpu.buf, img.width * img.height * 2);
    copy(tmp.buf, tmp_gpu.buf, tmp.width * tmp.height * 2);

    for benchmark_acc() {
        acc(acc_dev(), grid, block, || @{
            let gid_x = acc_gidx();
            let gid_y = acc_tidy() + acc_bdimy() * acc_bidy() * unroll;
            let out_acc = get_acc_i16(out_gpu, 10);
            let img_acc = get_acc_i16(img_gpu, 10);
            let tmp_acc = get_acc_i16(tmp_gpu, 10);

            for i in range(0, unroll) {
                body(gid_x, gid_y + i * acc_bdimy(), out_acc, img_acc, tmp_acc);
            }
        });
    }

    copy(out_gpu.buf, out.buf, out.width * out.height * 2);
    release(out_gpu.buf);
    release(img_gpu.buf);
    release(tmp_gpu.buf);
}
fn reduce(img: Imgi16, body: fn(i32, i32, Imgi16) -> i32) -> i32 {
    // temporary memory for reduction
    let tmp_buf = alloc_cuda(acc_dev(), img.width * 32);
    let mut tmp = tmp_buf.data as &[i32];

    let img_gpu = get_img_i16(alloc_cuda(acc_dev(), img.width * img.height * 2), img.width, img.height);
    copy(img.buf, img_gpu.buf, img.width * img.height * 2);

    // reduce all lines to temporary memory
    let grid1  = (img_gpu.width, 1, 1);
    let block1 = (128, 1, 1);
    for benchmark_acc() {
        acc(acc_dev(), grid1, block1, || @{
            let img_acc = get_acc_i16(img_gpu, 4);
            let mut sum = 0;
            for y in $range(0, img_gpu.height) @{
                sum += body(acc_gidx(), y, img_gpu);
            }
            tmp(acc_gidx()) = sum;
        });
    }

    // reduce temporary memory
    let grid2  = (img_gpu.width, 1, 1);
    let block2 = (128, 1, 1);
    for benchmark_acc() {
        acc(acc_dev(), grid2, block2, || @{
            let mut sum = 0;
            for x in $range(0, img_gpu.width) @{
                sum += tmp(x);
            }
            tmp(0) = sum;
        });
    }

    // return sum stored in first element
    let sum_buf = alloc_host(4 * 1);
    copy(tmp_buf, sum_buf, 4);
    let sum = (sum_buf.data as &[i32])(0);
    release(sum_buf);
    release(tmp_buf);
    release(img_gpu.buf);
    sum
}
fn histogram(img: Img, body: fn(i32, i32, Img) -> i32) -> Buffer {
    let hist_buf = alloc_host(256 * 4);
    let mut hist = hist_buf.data as &[i32];

    let grid   = (img.width, 1, 1);
    let block  = (256, 1, 1);
    for benchmark_acc() {
        acc(acc_dev(), (256, 1, 1), (128, 1, 1), || @{
            hist(acc_gidx()) = 0;
        });
        acc(acc_dev(), grid, block, || @{
            let mut sm_hist = reserve_shared(256 * 4) as &[i32];
            for y in $range(0, img.height) @{
                let bin = body(acc_gidx(), y, img);
                atomic_add_local(&sm_hist(bin), 1);
            }
            atomic_add_global(&hist(acc_tidx()), sm_hist(acc_tidx()));
        });
    }

    hist_buf
}
fn inclusive_scan(hist_buf: Buffer, size: i32, body: fn(i32, Buffer) -> i32) -> Buffer {
    let scan_buf = alloc_cuda(acc_dev(), size * 4);
    let mut scan = scan_buf.data as &[i32];
    let     hist = hist_buf.data as &[i32];

    // perform scan per block in shared memory first
    let block_size = 256;
    let num_blocks = size / (2 * block_size);
    let tmp_buf = alloc_cuda(acc_dev(), num_blocks * 4);
    let mut tmp = tmp_buf.data as &[i32];

    fn for_shift_down(a: i32, b: i32, body: fn(i32, fn())) -> () {
        if a > b {
            body(a);
            for_shift_down(a>>1, b, body, return)
        }
    }
    fn for_shift_up(a: i32, b: i32, body: fn(i32, fn())) -> () {
        if a < b {
            body(a);
            for_shift_up(a<<1, b, body, return)
        }
    }

    let grid   = (size / 2, 1, 1);
    let block  = (block_size, 1, 1);
    for benchmark_acc() {
        acc(acc_dev(), grid, block, || @{
            let gid = acc_gidx();
            let tid = acc_tidx();
            let sm_size = 2 * block_size;
            let mut sm_tmp = reserve_shared(sm_size * 4) as &[i32];

            // load input into shared memory
            sm_tmp(2 * tid)     = hist(2 * gid);
            sm_tmp(2 * tid + 1) = hist(2 * gid + 1);

            let mut offset = 1;
            for d in for_shift_down(sm_size >> 1, 0) { // build sum in place up the tree
                acc_barrier();
                if tid < d @{
                    let ai = offset * (2 * tid + 1) - 1;
                    let bi = offset * (2 * tid + 2) - 1;
                    sm_tmp(bi) += sm_tmp(ai);
                }
                offset *= 2;
            }

            // clear the last element: exclusive scan only
            // if tid == 0 { sm_tmp(sm_size - 1) = 0; }

            // traverse down tree & build scan
            for d in for_shift_up(1, sm_size) {
                offset >>= 1;
                acc_barrier();
                if tid < d @{
                    let ai = offset * (2 * tid + 1) - 1;
                    let bi = offset * (2 * tid + 2) - 1;
                    let tmp = sm_tmp(ai);
                    sm_tmp(ai) = sm_tmp(bi);
                    sm_tmp(bi) += tmp;
                }
            }

            acc_barrier();

            // write results to device memory
            if tid == 0 @{
                tmp(acc_bidx()) = sm_tmp(sm_size - 1);
            }
            scan(2 * gid)     = sm_tmp(2 * tid);
            scan(2 * gid + 1) = sm_tmp(2 * tid + 1);
        });
    }

    if num_blocks > 1 {
        // perform scan on block scan results
        let grid1  = (num_blocks, 1, 1);
        let block1 = (num_blocks, 1, 1);
        for benchmark_acc() {
            acc(acc_dev(), grid1, block1, || @{
                let tid = acc_tidx();
                let sm_size = num_blocks;
                let mut sm_tmp = reserve_shared(sm_size * 4) as &[i32];

                // load input into shared memory
                sm_tmp(tid) = tmp(tid);

                acc_barrier();

                if tid == 0 @{
                    let mut sum = sm_tmp(0);
                    for d in range(1, sm_size) {
                        sum += sm_tmp(d);
                        sm_tmp(d) = sum;
                    }
                }

                acc_barrier();

                // write results to device memory
                tmp(tid) = sm_tmp(tid);
            });
        }

        // add block scan results to array
        let grid2  = ((num_blocks-1) * block_size, 1, 1);
        let block2 = (block_size, 1, 1);
        for benchmark_acc() {
            acc(acc_dev(), grid2, block2, || @{
                let tid = acc_tidx();
                let gid = acc_gidx() + block_size; // first block hold already the correct scan results
                let mut sm_tmp = reserve_shared(1 * 4) as &[i32];

                if tid == 0 @{
                    sm_tmp(0) = tmp(acc_bidx());
                }

                acc_barrier();

                // write results to device memory
                scan(gid) += sm_tmp(0);
            });
        }
    }

    release(tmp_buf);
    scan_buf
}
fn find_position(scan: Buffer, size: i32, body: fn(i32, Buffer) -> i32) -> i32 {
    let elem_buf = alloc_cuda(acc_dev(), 1 * 4);
    let mut elem = elem_buf.data as &[i32];
    let size_buf = Buffer { device : 0, data : size as &[i8] };
    copy(size_buf, elem_buf, 4 * 1);

    let grid   = (size, 1, 1);
    let block  = (256, 1, 1);
    for benchmark_acc() {
        acc(acc_dev(), grid, block, || @{
            if body(acc_gidx(), scan) != 0 @{
                atomic_min_global(&elem(0), acc_gidx());
            }
        });
    }

    let result:i32;
    let r_buf = Buffer { device : 0, data : result as &[i8] };
    copy(elem_buf, r_buf, 4 * 1);
    release(elem_buf);
    result
}
